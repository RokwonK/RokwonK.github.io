---
layout: default
parent: Archive
title: "[운영체제] 가상 메모리 관리"
categories: CS
tags:
  - OS
  - 메모리
---  


프로세스의 크기가 메인 메모리보다 크다면 어떡할까? 프로그램을 실행하면 메인 메모리에 올라가게 된다. 하지만 프로그램의 크기가 이 보다 크다면 프로그램을 몇 개의 모듈로 나누고 필요한 부분만 메모리로 가져와 실행한다.

여기서 가상메모리라는 개념이 나온다. **프로세스는 여러 모듈로 나누어지고 사용중인 모듈은 메인 메모리상에 사용되지 않는 모듈은 디스크 공간(그 중 Swap 영역)에 남는다.** 그리고 실제로는 모든 메모리를 사용하는 것처럼 보여주기 위해 가상 주소(논리 주소) 번지를 가지는 논리적인 메모리를 공간을 이용한다. 이 공간의 각 주소에는 해당 가상주소가 가리키는 메인 메모리 주소 또는 디스크 주소를 가지고 있다.  

즉, **가상 메모리는 프로세스 공간 중 사용하는 부분(메인 메모리) + 현재 사용중이지 않는 부분(디스크 내 Swap 영역)을 논리적으로 하나의 메모리 공간으로 합친 개념**{: .font-highlight}이다.  

![virtual_memory](https://github.com/the-pool/the-pool-api/assets/52196792/c7b89dd6-b2ad-469f-a82a-99c6f1b008e4){: .align-center style="width: 60%;"}  
가상메모리
{: .image-caption style="font-size: 14px;" }  

**가상 메모리를 이용하면 프로그램이 실행되기 위한 최소한의 공간만을 사용하여 메모리 공간을 효율적으로 사용할 수 있다.** 사용하지 않는 부분까지 메인 메모리에 가지고 있다면 메인 메모리의 공간이 낭비된다. 그렇게 되면 다른 프로세스가 이용할 공간이 부족해지기 때문이다. 현대의 대부분의 OS는 가상 메모리 이용한다.  

**💡 Swap 영역**  
디스크 상에 존재하는 가상 메모리의 일부분
{: .notice}  

**💡 가상주소를 통해 접근하는 주소가 Swap영역에 있다면?**  
해당 영역을 메인 메모리로 올리기 위해서 페이지 교체 알고리즘이 동작한다. 가상메모리를 관리하는 방법에 대해서는 가상메모리 포스트에서 더 자세하게 알아보자.
{: .notice--info}


### 가상 메모리 공간
- 하드디스크 상에 **swap memory 공간이 존재**, 물리 메모리의 용량이 부족할때 사용
- swap out : 메모리 용량 부족시, 메모리 -> 하드 디스크로 일시적으로 이동
- swap in : 메모리 용량 충분, 하드디스크 -> 메모리

가상 메모리 또한 논리적이지만 메모리 공간이다. 
가상 메모리는 **가상 메모리를 물리 메모리에 매핑(적재)하는 방법**, **하드웨어의 Swap 영역에 존재하는 메모리를 물리 메모리로 Swaping하는 방법**에 따라 메모리, 시간적인 효율이 달라진다. 따라서 두 방법을 최적화하는 것이 성능에 큰 영향을 미친다.  

가상메모리를 물리 메모리에 어떻게 매핑할것인가 - 가상 메모리 분할 방식(페이징, 세그먼테이션)
어떤 방식 언제 Swap영역에서 물리메모리로 Swaping 할 것인가 - 페이지 교체


<br />  

### 가상 메모리 분할 방식 - Paging
고정분할 방식(내부 단편화 문제 발생)
- 가상 메모리를 page 단위로 분할
- 물리 메모리를 frame 단위로 분할, 비연속 할당
- page의 크기과 frame의 크기가 같음

**page table**  
- page와 frame 매핑 테이블
- 프로세스당 1개이며 물리 메모리의 OS 영역에 존재
- PCB 내의 PTBR에 page table의 시작 주소를 저장함
- MMU가 가상주소 -> 물리주소로 변환

**가상 주소 표현**  
- VA(Virtual Address) = <P(page 번호), D(page offset)>

**물리 주소 표현**  
- PA(Physical Address) = <F(frame 번호), D(frame offset)>

**paging의 문제점**  
- page 단위로 분환되어 page table의 크기가 큼(물리 메모리의 OS 영역이 증가)
- 따라서, 물리 메모리가 작으면 page table은 swap 영역으로 옮김

**page table 줄이기**
1. 직접 매핑
  - page table 전체가 물리 메모리의 OS 영역에 있음
  - 주소변환 빠르지만 물리 메모리 낭비
2. 연관 매핑
  - pt의 전체가 swap 영역, 일부는 OS 영역(TLB, 캐시 같은 느낌)
  - TBL hit, miss
  - 주소 변환이 느림
3. 집합-연관 매핑
  - pt를 여러개 set으로로 나누는 것
  - pt의 전체가 swap 영역, 일부 set은 OS 영역(캐시)
  - directory table(OS 영역에 존재)을 가지고 set이 물리메모리에 있는지 확인
  - 연관 매핑보다 주소 변환이 빠름
4. 역 매핑
  - frame 번호 순으로 작성, PID와 page 번호로 구성
  - PID를 가짐으로 프로세스 수와 상관없이 1개의 inverted page table을 가짐
  - 물리 메모리를 절약할 수 있음
  - PID와 page 번호를 모두 검색하므로 주소 변환이 느림


### 가상 메모리 분할 방식 - Segmentation
가변분할 방식(외부 단편화 문제 발생)  
segment(논리 단위) - 프로세스 내의 서로 관련있는 영역
- 가상 메모리를 segment 단위로 분할
- 물리 메모리를 segment 단위로 분할, 비연속 할당

**segment table**  
- 가상주소, 물리주소 매핑 테이블
- 프로세스당 1개, OS영역에 존재
- limit(segment의 크기), base(segment의 물리 메모리 상의 시작주소)로 구성됨  

**paging의 문제점**  
- 메모리 관리가 복잡


### 가상 메모리 분할 방식 - Hybrid
**page에 대한 접근 권한 설정 시 문제**  
- 메로리 영역별 서로 다른 접근 권한을 줘야함
- 권한 비트가 pt에 추가 -> 중복 발생


**혼용 기법으로 해결 - 페이징을 기반으로 세그먼테이션 사용**  
- page로 분할된 가상 메모리에 서로 관련 있는 영역을 segment롤 묶기
- page table -> segment table -> 물리주소 순서로 접근

**장점**  
- Paging을 사용하여 외부 단편화가 생기지 않음
- Segmentation을 사용하여 page table의 크기를 줄임  

<br />  
<br />  

## 가상 메모리 관리하기


### 요구 페이징(demand paging)
- 프로세스가 요구하는 페이지만 물리 메모리로 가져오고 나머지는 swap 영역에 저장하는 가상 메모리 관리 방법, 호출되지 않은 페이지와 swap out된 페이지가 swap 영역에 있다.
- pre-paging
  - 예상되는 페이지를 미리 물리 메모리로 가져오는 방식
  - 쓸모 없을 경우 메모리 낭비가 큼
  - 따라서, 현대 OS는 요구 페이징을 기본으로 함

가상메모리의 - Page Table Entry
- frame 번호(물리 메모리 프레임 번호, swap 영역내 페이지 주소)
- flag bit(물리 메모리에 있으면 1)

page fault
- 프로세스가 요구하는 페이지가 물리 메모리에 없고 swap 영역에 있는 경우 swap in 
- 만약 물리 메모리가 꽉 찬 경우 대상 페이지를 선택해서 swap out 해야함
- 대상 페이지를 결정하는 알고리즘이 페이지 교체 알고리즘(page fault rate을 낮추는게 목적)

<br />  

### 페이지 교체 알고리즘  

간단한 알고리즘(random, FIFO), 최적 알고리즘, 최적 근접 알고리즘(LRU, LFU, NUR)로 나누어짐.

**Random**  
- 임의로 정한 페이지를 swap out
- 성능이 좋지 않음  

**FIFO**  
- 가장 먼저 swap in한 페이지를 가장 먼저 swap out  
- 가장 오래된 페이지도 물리 메모리 상에서 자주 사용될 수 있음
- page fault rate 증가

**최적 페이지 교체**
- 미리에 가장 오랫동안 사용되지 않을 페이지를 swap out
- 가장 좋은 성능이지만 미래를 알 수 없기에 실제로 구현은 불가능
- 이 성능에 근접하면서 실제로 구현 가능한 최적 근접 페이지 교체 알고리즘들이 제안됨  

**LRU(least recently used)**  
- 최근에 가장 오랫동안 사용되지 않은 페이지 swap out
- FIFO 페이지 교체 알고리즘보다 우수
- 각 페이지의 접근 시간을 PTE에 저장해 **추가적인 메모리가 요구**됨  
- Counter(순서)와 Reference bit Shift(비트 이동) 기반한 구현이 존재  

**LFU(least frequently used)**
- 사용 빈도가 가장 낮은 페이지 swap out
- LRU와 성능이 비슷
- 접근 빈도를 저장하기 위한 추가적인 메모리가 요구됨

**NUR(not used recently)**
- 사용성이 낮은 페이지를 swap out
- 각 페이지의 PTE 내 access bit, modify bit 사용
- 페이지를 참조한 경우 access bit 1, 수정한 경우 modify bit 1, 레벨로 나누고 낮은 레벨이 대상 페이지로 선정됨
- LFU, LRU와 비슷한 성능이지만 메모리 낭비가 적어 가장 많이 사용되는 알고리즘

<br />  

### 잦은 페이지 교체 - Thrashing  
다수의 프로세스가 동시에 몰리면 **물리 메모리가 부족해지고 잦은 페이지 교체가 일어난다. 이로 인해 CPU 사용률이 급격히 저하**된다.(페이지 교체 시간동안 CPU가 대기 상태이므로) 이러한 상태를 `Thrashing` 이라고 부른다. 이 문제를 해결하기 위한 몇가지 방법이 존재한다. 

1. **물리 메모리 크기 증가**  
메모리가 부족하니 메모리를 늘린다! 가장 근본적인 문제를 해결하는 방법이지만 비용 등 한계가 존재한다.  
2. **작업집합 모델**  
시간의 지역성을 바탕으로 최근 일정 시간동안 참조된 페이지들의 집합을 만들어 물리 메모리에 유지시킨다. 작업집합에 속하지 않는 페이지들을 페이지 교체 대상으로 선정한다. 작업집합은 주기적으로 갱신된다.
3. **Page fault frequency**  
페이지 부재(page fault) 빈도를 통해서 page fault rate를 계산하고 분석하여 개선점을 파악한다. 하한선(lower bound)과 상한선(upper bound)을 정하고 page fault rate가 상한선 보다 높으면 적은 frame이 할당되어 잦은 page fault가 발생하는 것이므로 프로세스에 추가적인 frame을 할당한다. 반대로 하한선보다 낮으면 메모리가 낭비되므로 프로세스에 할당된 frame을 회수한다.